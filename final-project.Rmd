---
title: "final project"
author: "Yuchen Zhang"
date: "2022-12-12"
output: html_document
---
```{r, include=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(corrplot)
library(ggplot2)
library(leaps)
library(glmnet)
library(caret)
library(modelr)
library(gtsummary)
library(interactions)
library(caret)
library(MASS)
set.seed(1)
```

### Distribution of Data ###
Import data
```{r}
Body_df = readxl::read_excel("data/body_density_data.xlsx")
tbl_summary(Body_df)
summary(Body_df)
```

We chose fat density of Brozek's function as outcome
```{r}
ggplot(Body_df, aes(x = bodyfat_brozek)) + 
 geom_histogram(aes(y = ..density..), color = "white", fill = "blue",binwidth = 1) +
 geom_density(alpha = .2) +
 labs(title = "Distributions of body fat measured in Brozek method")

```

Here are the distribution of all the variables
```{r}
colnames = colnames(Body_df)
for (i in 5:17) {
  plot = 
ggplot(Body_df, aes_string(x = colnames[i])) + 
 geom_histogram(aes(y = ..density..), color = "white", fill = "blue",binwidth = 1) + 
 geom_density(alpha = .2) +
 labs(title = sprintf("Distributions of %s", colnames[i]) )
  
  print(plot)
}
```

```{r}
colnames = colnames(Body_df)
for (i in 5:17) {
  plot = 
ggplot(Body_df, aes_string(y = colnames[i])) + 
 geom_boxplot() + 
 labs(title = sprintf("Distributions of %s", colnames[i]) )
  
  print(plot)
}
```

Here are the correlation between the bodyfat_brozek with the predictors 
```{r,message = FALSE, warning = FALSE}
for (i in 5:17) {
  plot = 
  Body_df %>% 
    ggplot(aes_string(x = colnames[i], y = "bodyfat_brozek")) + geom_point() + geom_smooth(method = 'lm', se = TRUE, color = 'red') +
    labs(title = sprintf("Scatter plot for body fat against %s", colnames[i]) ) +
    ylab("Body Fat (Brozek)")
  
  print(plot)
}
```

Here, we clean the data 
```{r}
bodyfat_selected = 
  Body_df %>% 
  dplyr::select(-id,-bodyfat_siri,-body_density)
```

Let's take a look on the interaction between the variables
```{r}
pairs(bodyfat_selected)
```
Correlat eplot
```{r}
corrplot(cor(bodyfat_selected), type = "upper", diag = FALSE)
```


## Linear Regression ## 
All the variables are normal and required no transformation.
Based the variables' we selected, let's firstly fit all them into a MLR model.
```{r}
multifit = lm(bodyfat_brozek ~ ., data = bodyfat_selected)
```


#### Automatic Selection ####
Backward Elmination
```{r}
step(multifit, direction = "backward")
```
The Final model obtained from Backward Elimination is 
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

Forward selection
```{r}
intercept_only = lm(bodyfat_brozek ~ 1, data = bodyfat_selected)
step(intercept_only, direction = "forward", scope = formula(multifit))
```
The model obtained from Forward Selection is 
__lm(formula = bodyfat_brozek ~ abdomen + weight + wrist + forearm + neck + age + thigh + hip, data = bodyfat_selected)__

Stepwise Selection
```{r}
step(multifit, direction = "both")
```
The stepwise selection from both side get us the model to be
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

From the procedures we done above, the fianl model was agreed to be __lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__


#### Tested Based Procedures ####
Then, let's try Tested Based Procedures
"Cp test"
```{r}
mat = as.matrix(bodyfat_selected)
leaps(x = mat[,2:14], y = mat[,1], nbest = 1, method = "Cp")
```
The smallest Cp value we got indicate that best model:
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

```{r}
leaps(x = mat[,2:14], y = mat[,1], nbest = 1, method = "adjr2")
```
The largest adjusted R2 indicated the best subset to be:
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data= bodyfat_selected)__

#### LASSO ####
Let's use corss validation to choose lambda
```{r}
lambda_seq = 10^seq(-3, 0, by = 0.1)
set.seed(1)
cv_bodyfat = cv.glmnet(as.matrix(bodyfat_selected[2:14]), bodyfat_selected$bodyfat_brozek, lambda = lambda_seq, nfolds = 5)
cv_bodyfat
```
The Lambda minimum is 0.0794. 
Then, let's reun a LASSO regression using this value.
```{r}
lasso_fit = glmnet::glmnet(as.matrix(bodyfat_selected[2:14]), bodyfat_selected$bodyfat_brozek, lambda = cv_bodyfat$lambda.min)
coef(lasso_fit)
```
The final model obtained from LASSO is
__lm(formula =bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)__

#### Model choose #### 
Stepwise selection and criterion test both indicate the same model. Though LASSO included height and bicep, the model is still similar. Further process would be done to choose from the LASSO model: __lm(formula =bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)__ and the small model  __lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data= bodyfat_selected)__. 


### Model Validation ###
Since the lasso method incurs a different model, so we will adopt model validation to choose the better model.
First, use 5-fold validation and create the training sets.
```{r}
train = trainControl(method = "cv", number = 5)
```
Then, fit the lasso model.
```{r}
model_lasso = train(bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, 
                    data = bodyfat_selected,
                    trControl = train,
                    method = "lm",
                    na.action = na.pass)

model_lasso$finalModel
```

```{r}
print(model_lasso)
```
RMSE for model_lasso is 4.077981; Rsquared is 0.7296759; MAE is 3.329993.
Now, fit the test_based model.
```{r}
model_test = train(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, 
                    data = bodyfat_selected,
                    trControl = train,
                    method = "lm",
                    na.action = na.pass)

model_test$finalModel
```

```{r}
print(model_test)
```
RMSE for model_test is 4.078487; Rsquared is 0.7310717; MAE is 3.340266
Since the RMSE and MAE are slightly smaller in the lasso model, we would slightly favor the lasso model. However, considering the principle of parsimony, we will run ANOVA to further compare the two models.

### ANOVA for MLR ###
```{r}
model_small = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, 
                    data = bodyfat_selected)
model_large = lm(bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)

anova(model_small,model_large)
```
F = 0.5015, p_value = 0.6062, we fail to reject H0 and conclude that the larger model is not superior. Now, according to the principle of parsimony, we will choose the small model. 
```{r}
model_1 = model_small
summary(model_1)
```

## Interaction ##
In the data exploration part, we can find that the correltaion between the varaibles are very significant. The predictors can interact with each other. Thus, let's check it again with our further selected data. 
```{r}
body_mod_select = bodyfat_selected %>%
  dplyr::select(bodyfat_brozek, age, weight, neck, abdomen, hip, thigh, forearm, wrist)
corrplot(cor(body_mod_select), type = "upper", diag = FALSE)
```
We can find that the correlation of the variables left are strong between each other, except age. 
Let's check their interactions.

```{r}
lm.fit2 = lm(bodyfat_brozek ~ (age + weight + neck + abdomen + hip + thigh + forearm + wrist)^2, 
             data = bodyfat_selected)
table = anova(lm.fit2)

inter_group = table %>%
  filter(`Pr(>F)` < 0.05)
```
From the table, based on the pvalue smaller than 0.05. We found that only the weight:neck and neck: abdomen's interaction are statistically significant. Thus, there two interactive groups would be included in the model. 

The improved model with interaction between significant associated predictors showed to be:
__model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight:neck + neck:abdomen, data = bodyfat_selected)__

```{r}
model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight*neck + neck*abdomen, data = bodyfat_selected)
summary(model_final)
```
Here, we got two candidate model. 
One without interactions: 
__model_1 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

Another one with interactions:
__model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight:neck + neck:abdomen, data = bodyfat_selected)__



### Boxcox Transformation




## Model Diagnostics ##
### Rediduals ###
```{r}
plot(model_1, which = 1)
plot(model_2, which = 1)
```







#### Residual vs Fitted & QQ Plots ####
Residual vs Fitted plot
```{r}
plot(model_final, which = 1)
```
Heteroscedasticity is not detected.

QQ plot
```{r}
plot(model_final, which = 2)
```
Residuals appear to be normal.
No transformations needed.

#### Checking to Outliers and Influential Points ####
Residuals vs Leverage plot
```{r}
plot(model_final, which = 4)
```
Since the Cook's distances are all smaller than 0.025, according to rule of thumb, there are no influential points of concern. 


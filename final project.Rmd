---
title: "final project"
author: "Yuchen Zhang"
date: "2022-12-12"
output: html_document
---
```{r, include=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(corrplot)
library(ggplot2)
library(leaps)
library(glmnet)
library(caret)
library(modelr)
library(gtsummary)
library(interactions)
library(caret)
library(MASS)
library(performance)
library(gridExtra)
set.seed(1)
```

## Data exploratory ##
### Distribution of Data ###
Import data
```{r}
Body_df = readxl::read_excel("data/body_density_data.xlsx")
tbl_summary(Body_df)
summary(Body_df)
```

We chose fat density of Brozek's function as outcome and here is the distribution of bodyfat_brozek
```{r}
ggplot(Body_df, aes(x = bodyfat_brozek)) + 
 geom_histogram(aes(y = ..density..), color = "white", fill = "light blue",binwidth = 1) +
 geom_density(alpha = .2) +
 labs(title = "Distributions of body fat measured in Brozek method")

```

Here are the distribution of all the variables shown in histogram
```{r}
colnames = colnames(Body_df)
pdf("histogram.pdf")
for (i in 5:17) {
  plot = 
ggplot(Body_df, aes_string(x = colnames[i])) + 
 geom_histogram(aes(y = ..density..), color = "white", fill = "light blue",binwidth = 1) + 
 geom_density(alpha = .2) +
 labs(title = sprintf("Distributions of %s", colnames[i]) )
  
  print(plot)
}
```

Here are the distribution of all the variables shown in boxplot
```{r}
colnames = colnames(Body_df)
pdf("boxplot.pdf")
boxplot=
  for (i in 5:17) {
  plot = 
ggplot(Body_df, aes_string(y = colnames[i])) + 
 geom_boxplot() + 
 labs(title = sprintf("Distributions of %s", colnames[i]) )
  
  print(plot)
}
```
From the distribution plots of the variables, we can find that, all the variables are in normal distribution with very few outliers. Thus, no transformation may be requried. 

Here, we clean the data 
```{r}
bodyfat_selected = 
  Body_df %>% 
  dplyr::select(-id,-bodyfat_siri,-body_density)
```

Here are the correlation between the bodyfat_brozek with the predictors 
```{r,message = FALSE, warning = FALSE} 
# Building scatter plots
pdf("correlation.pdf")
correlation = 
for (i in 5:17) {
  plot = 
  Body_df %>% 
    ggplot(aes_string(x = colnames[i], y = "bodyfat_brozek")) + geom_point() + geom_smooth(method = 'lm', se = TRUE, color = 'red') +
    labs(title = sprintf("Scatter plot for body fat against %s", colnames[i]) ) +
    ylab("Body Fat (Brozek)")
  
  print(plot)
}
```

```{r}
# Pair the variables
pair = pairs(bodyfat_selected)
```

```{r}
# Corrplot the variables
corplot = corrplot(cor(bodyfat_selected), type = "upper", diag = FALSE)
```

We can find that, most of the variables have linear correlation with others. It should be paid attention in later data analysis. 


## Building models ## 
All the variables are normally distributed and required no transformation.
As the outcome and predictors are all quantitative data, it would be improper to fit the model in Logistic Regression or exponential regression. Thus linear regression may be still the best choice for use to build the model. 

Let's firstly build fit all the variables in a Multiple linear regression model. 
```{r}
multifit = lm(bodyfat_brozek ~ ., data = bodyfat_selected)
```

### Linear Regression ###
#### Automatic Selection ####
Backward Elmination
```{r}
step(multifit, direction = "backward")
```
The Final model obtained from Backward Elimination is 
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

Forward selection
```{r}
intercept_only = lm(bodyfat_brozek ~ 1, data = bodyfat_selected)
step(intercept_only, direction = "forward", scope = formula(multifit))
```
The model obtained from Forward Selection is 
__lm(formula = bodyfat_brozek ~ abdomen + weight + wrist + forearm + neck + age + thigh + hip, data = bodyfat_selected)__

Stepwise Selection
```{r}
step(multifit, direction = "both")
```
The stepwise selection from both side get us the model to be
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

From the procedures we done above, the fianl model was agreed to be __lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__


#### Tested Based Procedures ####
Then, let's try Tested Based Procedures
"Cp test"
```{r}
mat = as.matrix(bodyfat_selected)
leaps(x = mat[,2:14], y = mat[,1], nbest = 1, method = "Cp")
```
The smallest Cp value we got indicate that best model:
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

```{r}
leaps(x = mat[,2:14], y = mat[,1], nbest = 1, method = "adjr2")
```
The largest adjusted R2 indicated the best subset to be:
__lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data= bodyfat_selected)__

#### LASSO ####
Let's use corss validation to choose lambda
```{r}
lambda_seq = 10^seq(-3, 0, by = 0.1)
set.seed(1)
cv_bodyfat = cv.glmnet(as.matrix(bodyfat_selected[2:14]), bodyfat_selected$bodyfat_brozek, lambda = lambda_seq, nfolds = 5)
cv_bodyfat
```
The Lambda minimum is 0.0794. 
Then, let's reun a LASSO regression using this value.
```{r}
lasso_fit = glmnet::glmnet(as.matrix(bodyfat_selected[2:14]), bodyfat_selected$bodyfat_brozek, lambda = cv_bodyfat$lambda.min)
coef(lasso_fit)
```
The final model obtained from LASSO is
__lm(formula =bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)__

### Model choose ### 
Stepwise selection and criterion test both indicate the same model. Though LASSO included height and bicep, the model is still similar. Further process would be done to choose from the LASSO model: __lm(formula =bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)__ and the small model  __lm(formula = bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data= bodyfat_selected)__. 


#### Model Validation ####
Since the lasso method incurs a different model, so we will adopt model validation to choose the better model.
First, use 5-fold validation and create the training sets.
```{r}
train = trainControl(method = "cv", number = 5)
```
Then, fit the lasso model.
```{r}
set.seed(1)
model_lasso = train(bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, 
                    data = bodyfat_selected,
                    trControl = train,
                    method = "lm",
                    na.action = na.pass)

model_lasso$finalModel

model_test = train(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, 
                    data = bodyfat_selected,
                    trControl = train,
                    method = "lm",
                    na.action = na.pass)

model_test$finalModel

print(model_lasso)
print(model_test)
```
The RMSE obtained from model_lasso is 4.077981 and that of model_test is 4.078487. The MAE obtained from model_lasso is 3.329993 and that of model_test is 3.340266.

As the RMSE and MAE are slightly smaller in LASSO model, it is more preferred. However, considering the principle of parsimony, we will run ANOVA to further compare the two models.

#### ANOVA for MLR ####
```{r}
model_small = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, 
                    data = bodyfat_selected)
model_large = lm(bodyfat_brozek ~ age + weight + height + neck + abdomen + hip + thigh + bicep + forearm + wrist, data = bodyfat_selected)

anova(model_small,model_large)
```
F = 0.5015, p_value = 0.6062, we fail to reject H0 and conclude that the larger model is not superior. Now, according to the principle of parsimony, we will choose the small model. 
```{r}
model_1 = model_small
summary(model_1)
```

## Interaction ##
In the data exploration part, we found that the correlation between the variables are very significant. The predictors can interact with each other. Thus, let's check it again with our further selected data. 
```{r}
body_mod_select = bodyfat_selected %>%
  dplyr::select(bodyfat_brozek, age, weight, neck, abdomen, hip, thigh, forearm, wrist)
corrplot(cor(body_mod_select), type = "upper", diag = FALSE)
```
We can find that the correlation of the variables left are strong between each other, except age. 
Let's check their interactions.

```{r}
lm.fit2 = lm(bodyfat_brozek ~ (age + weight + neck + abdomen + hip + thigh + forearm + wrist)^2, 
             data = bodyfat_selected)
table = anova(lm.fit2)

inter_group = table %>%
  filter(`Pr(>F)` < 0.05)

inter_group
```
From the table, based on the pvalue smaller than 0.05. We found that only the weight:neck and neck: abdomen's interaction are statistically significant. Thus, these two interactive groups would be included in the model. 

The model with interaction between significant associated predictors is:
__model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight:neck + neck:abdomen, data = bodyfat_selected)__

```{r}
model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight*neck + neck*abdomen, data = bodyfat_selected)
summary(model_2)
model_2_table = broom::tidy(summary(model_2))
```


Here, we got two candidate model. 
One without interactions: 
__model_1 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)__

Another one with interactions:
__model_2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight:neck + neck:abdomen, data = bodyfat_selected)__



## Model Diagnostics ##
### Rediduals vs Fitted plot###
```{r}
plot(model_1, which = 1)  
plot(model_2, which = 1)  
```
Horizontal bands around 0 are formed, indicating no heteroscedasticity and outliers were detected. 

### Normal QQ plot ###
```{r}
plot(model_1, which = 2) 
plot(model_2, which = 2) 
```
Straight lines were observed, indicating the residuals are normal. 

### Scale-Location plot ###
```{r}
plot(model_1, which = 3) 
plot(model_2, which = 3) 
```
In each plot, the points were equally distributed with a horizontal line. 

### Outliers and Leverage ###
Cook's distance plot. 
```{r}
plot(model_1, which = 4)  #39, #175, #216
plot(model_2, which = 4)  #3, #216, #250 
```
There are in total 252 samples used to build our models, so the rule of thumb for Cook's distance is D > 4/n = 0.016. There were some influential outliers were detected. Further process of outliers are required. 

Let's remove the influential points.
```{r}
bodyfat_out_1 = bodyfat_selected[-c(39,175,216),]
bodyfat_out_2 = bodyfat_selected[-c(3,216,250),]
```

Then, let's fit the model with and without influential points. 
__Check model_1__
```{r}
with1 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_selected)

without1 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_out_1)

summary(with1)
summary(without1)
```
check without1 diagnostics
```{r}
plot(without1)
```

check model 2
```{r}
with2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight*neck + neck*abdomen, data = bodyfat_selected)

without2 = lm(bodyfat_brozek ~ age + weight + neck + abdomen + hip + thigh + forearm + wrist + weight*neck + neck*abdomen, data = bodyfat_out_2)

summary(with2)
summary(without2)
```
check without2 diagnostics
```{r}
plot(without2)
```

Both plots without influential point showed to better than those with influential points. 

### Colinearility
```{r}
corrplot(cor(bodyfat_out), type = "upper", diag = FALSE)
```
Still, even after excluding the influential data, all the predictors, except age, are highly correlated. 

Let's check the model without interactions terms.
```{r}
check_collinearity(without1)
```
It's found that, there VIF value is very high for weight, hip and abdomen terms, indicating their strong correlation with other variables. 

Let's remove the weight term with highest VIF. 
```{r}
without1_new = lm(bodyfat_brozek ~ age + neck + abdomen + hip + thigh + forearm + wrist, data = bodyfat_out)
check_collinearity(without1_new)
```
The correlation between the variables is lowered, but we still have hip(8.61), thigh(5.64) and abdomen(6.26) with high VIF. Then we remove the hip term.  
```{r}
without2_new = lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist, data = bodyfat_out)
check_collinearity(without2_new)
```
After removing these two variables, we have got all predictors with low VIF. 

The final model we will have with and without interaction would be. 
```{r}
model_1f = lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist, data = bodyfat_out)
summary(model_1f)

model_2f = lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist + neck*abdomen, data = bodyfat_out)
summary(model_2f)
```

## Cross validation ##
Let's create RMSE distribution boxplot
```{r}
set.seed(2)
cv_df = crossv_mc(bodyfat_out, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>%
  mutate(
    mod_1 = map(.x = train, ~lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist, data =.x)),
    mod_2 = map(.x = train, ~lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist + neck*abdomen, data =.x))
  ) %>%
  mutate(
    rmse_1 = map2_dbl(.x = mod_1, .y = test, ~rmse(model = .x)),
    rmse_2 = map2_dbl(.x = mod_2, .y = test, ~rmse(model = .x))
  )

rmse_boxplot = cv_df %>%
  dplyr::select(rmse_1, rmse_2) %>%
  pivot_longer(rmse_1:rmse_2,
               names_to = "model",
               values_to = "rmse",
               names_prefix = "remse_") %>%
  ggplot(aes(x = model, y = rmse)) + geom_boxplot() +
  labs(x = "Model", y = "RMSE")

rmse_boxplot
```
By plotting the RMSE distribution of two model, we can find that the interaction model has the lower RMSE, which is more prefered.  

```{r}
set.seed(2)
train = trainControl(method = "cv", number = 10)

mod_1_cv = train(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist, data = bodyfat_out, trControl = train, method = "lm", na.action = na.pass)

mod_2_cv = train(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist + neck*abdomen, data = bodyfat_out, trControl = train, method = "lm", na.action = na.pass)

RMSE = bind_rows(
  as_tibble(mod_1_cv$results),
  as_tibble(mod_2_cv$results)
) %>%
  knitr:: kable(digit = 3)
RMSE
```

Model 2's RMSE(3.966) is slightly smaller than that of model 1(3.979). 

Finally, based on the data analysis, the final model we would choose to is the model 2 with interactions terms. 

The final model would be
```{r}
final_model = lm(bodyfat_brozek ~ age  + neck + abdomen + thigh + forearm + wrist + neck*abdomen, data = bodyfat_out)
summary(final_model)
broom::tidy(summary(final_model))
```
__bodyfat_brozek = -57.2 + 0.104*age + 0.774*neck + 1.19*abdomen + 0.102*thigh + 0.339*forearm -2.1*wrist - 0.013*neck:abdomen__







